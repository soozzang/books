# 02. 대규모 데이터 처리 입문

---

# 강의 5. 대규모 데이터 처리의 어려운 점
## 대규모 데이터는 어떤 점이 어려운가?
> 메모리 내에서 계산할 수 없다

제1 포인트는 `메모리 내에서 계산할 수 없다`는 점이다. 

메모리 내에서 계산할 수 없다는 점이 어려운 점인 이유는 메모리에 올리지 않으면 기본적으로 디스크를 계속 읽어가면서 검색하게 되어 좀처럼 발견할 수 없는 상태가 되기 때문이다.

데이터 건수가 많으면 그만큼 입력 데이터 건수가 늘어나서 계산량이 많아지는 점도 당연한 이유지만, 가장 큰 문제는 `디스크를 읽고 있다`는 점이다.

## 메모리와 디스크의 속도차
> 메모리는 10^5 ~ 10^6배 이상 고속

메모리 내의 특정 번지에 있는 데이터를 찾는 데이터 탐색과 디스크의 특정 원반 내에 있는 데이터를 찾는 것은 얼마의 속도차이가 날까?

10만~100만 배정도 난다.

## 디스크는 왜 늦을까?
> 메모리와 디스크

메모리는 전기적인 부품이므로 물리적 구조는 탐색속도와 그다지 관계없다.

디스크는 동축 상에 '원반(disk)'가 쌓여 있다. 이 원반이 회전하고 있고 여기서 데이터를 읽어낸다. 즉, 메모리와는 달리 회전 등의 물리적인 동작을 수반하고 있다. 이 물리적 구조가 탐색 속도에 영향을 준다.

### 탐색속도에 영향을 주는 다양한 요인
디스크에서는 헤드의 이동과 원반의 회전이라는 두 가지 물리적 이동이 필요하지만, 역시나 오늘날의 기술로도 원반의 회전속도를 빛의 속도까지 근접시킬 수는 없다.

디스크는 위 두가지 작업이 밀리초 단위, 합해서 수 밀리초나 걸린다. 메모리는 1회 탐색할 때 마이크로초면 되지만, 디스크는 수 밀리초가 걸리는 것이다.

또, 데이터가 뿔뿔이 흩어져서 배치되어 있고 이분탐색 등 여기저기에서 찾아야 하는 알고리즘을 사용한다면, 한 바퀴 회전해서 이쪽으로 이동하고 또 한 바퀴 회전해서 저쪽으로 원반을 빙글빙글 돌려야 한다.

그러나 데이터가 메모리 상에 있다면 탐색할 때 물리적인 동작 없이 실제 데이터 탐색 시의 오버헤드가 거의 없으므로 빠른 것이다.

## OS 레벨에서의 연구
드스크는 느리지만 OS는 이것을 어느정도 커버하는 작용을 한다.

OS는 연속된 데이터를 같은 위치에 쌓는다. 그리고 나서 데이터를 읽을 때 1바이트씩 읽는 것이 아니라 4KB 정도를 한꺼번에 읽도록 되어 있다.

이렇게 해서 비슷한 데이터를 비슷한 곳에 두어 1번의 디스크 회전으로 읽는 데이터 수를 많게 한다.

이러한 작용을 해서 디스크를 가능한 한 회전시키지 않아도 되도록 하고 있다.

그렇지만 결국 회전 1회당 밀리초 단위이므로 역시 메모리와의 속도차를 피할 수 있는 것은 아니다.

## 전송속도, 버스의 속도차
이제 전송속도 차이도 살펴보자.

메모리나 디스크 모두 CPU와 버스로 연결되어 있다.

이 버스의 속도에서도 상당한 차이가 있다.

먼저 `탐색`과 `전송`의 차이에 유의하기 바란다.

앞서 본 것은 메모리 혹은 디스크상에 있는 임의의 데이터를 탐색할 때의 속도차, 여기서 살펴보고자 하는 것은 전송속도다.

`찾은 데이터`를 `디스크에서 메모리로` 보내거나 메모리에서 CPU로 보내는 등 컴퓨터 내부에서 전송하기 위한 속도다.

메모리와 CPU는 상당히 빠른 버스로 연결되어 있으므로 7.5GB/초 정도 나오지만 디스크는 58MB/초 정도밖에 나오지 않는다.

따라서 전송해오는 중에도 시간이 걸린다.

최근 SSD가 나오고 있다. SSD는 물리적인 회전이 아니므로 탐색은 빠르지만 버스 속도가 병목이 되거나 그 밖에 구조에 기인하는 면이 있어서 역시 메모리만큼의 속도는 나오지 않는다.

> 전송속도에서도 100배 이상 차이가 난다.

---

"추측하지 말라, 계측하라"

부하분산의 세계도 예외없이 이에 해당한다. 계측함으로써 시스템의 병목을 규명하고, 이를 집중적으로 제거함으로써 성능을 끌어낼 수 있다.

### Load Average 확인
Load Average는 시스템 전체의 부하상황을 나타내는 지표이다.

다만, Load Average만으로는 병목의 원인이 어딘지를 판단할 수 없다. 이 값을 시초로 해서 병목지점에 대한 조사를 시작한다.

Load Average는 낮은데 시스템의 전송량이 오르지 않을 경우도 가끔 있다. 이럴 경우는 소프트웨어의 설정이나 오류, 네트워크, 원격 호스트 측에 원인이 없는지 등을 살펴본다.

### CPU, I/O 중 병목 원인 조사
Load Average가 높은 경우, 다음으로 CPU와 I/O 어느 쪽에 원인이 있는지를 조사한다.

sar이나 vmstat로 시간 경과에 따라 CPU 사용률이나 I/O 대기율의 추이를 확인할 수 있다.

확인 후 다음 단계로 나아간다.

`CPU 부하`가 높을 경우, 다음과 같은 흐름을 따라 조사해간다.

- 사용자 프로그램의 처리가 병목인지, 시스템 프로그램이 원인인지를 확인한다. top이나 sar로 확인한다.
- ps로 볼 수 있는 프로세스의 상태나 CPU 사용시간 등을 보면서 원인이 되고 있는 프로세스를 찾는다.
- 프로세스를 찾은 후 보다 상세하게 조사할 경우는 strace로 추적하거나 oprofile로 프로파일링을 해서 병목지점을 좁혀간다.

일반적으로 CPU에 보하가 걸리고 있는 것은 다음 상황 중 하나다.
- 디스크나 메모리 용량 등 그 밖의 부분에서는 병목이 되지 않는, 말하자면 `이상적인` 상태
- 프로그램이 폭주해서 CPU에 필요이상의 부하가 걸리는 경우

전자의 상태에다 시스템의 전송량에 문제가 있다면 서버 증설이나 프로그램의 로직이나 알고리즘을 개선해서 대응한다. 후자의 경우는 오류를 제거해서 프로그램이 폭주하지 않도록 대처한다.

`I/O`부하가 높은 경우, 프로그램으로부터 입출력이 많아서 부하가 높거나 스왑이 발생해서 디스크 액세스가 발생하고 있는 상황 중 하나일 경우가 대부분이다. sar이나 vmstat로 스왑의 발생상황을 확인해서 문제를 가려낸다.

확인 결과 스왑이 발생하고 있을 경우는 다음과 같은 점을 실마리로 조사한다.
- 특정 프로세스가 극단적으로 메모리를 소비하고 있지 않은지를 ps로 확인할 수 있다.
- 프로그램의 오류로 메모리를 지나치게 사용하고 있는 경우에는 프로그램을 개선한다.
- 탑재된 메모리가 부족한 경우에는 메모리를 증설한다.

스왑이 발생하지 않고 디스크로의 입출력이 빈번하게 발생하고 있는 상황은 캐시에 필요한 메모리가 부족한 경우를 생각해볼 수 있다.

해당 서버가 저장하고 있는 데이터 용량과 증설 가능한 메모리 양을 비교해서 다음과 같이 나눠서 검토한다.
- 메모리 증설로 캐시영역을 확대시킬 수 있는 경우는 메모리를 증설한다.
- 메모리 증설로 대응할 수 없는 경우는 데이터 분산이나 캐시서버 도입 등을 검토한다.

I/O 성능을 개선하기 위해서는 다음과 같은 것을 규명할 필요가 있다.
- 메모리를 증설해서 캐시 영역을 확보함으로써 대응할 수 있는가
- 원래 데이터량이 너무 많지는 않은가
- 애플리케이션 측의 I/O 알고리즘을 변경할 필요가 있는가

<br>

# 강의 6. 규모조정의 요소
이번엔 위와 같은 상황들이 시스템 전체의 확장성 전략에 어떤 영향을 줄지에 대해 살펴보도록 하자.

웹 서비스에서는 고가의 빠른 하드웨어를 사서 성능을 높이는 스케일업 전략보다도 저가이면서 일반적인 성능의 하드웨어를 많이 나열하여 시스템 전체 성능을 올리는 스케일아웃 전략이 주류이다.

유연성도 챙길 수 있다. 이때 시스템 구성의 유연성이라는 것은 생각하기 나름인데, 부하가 적을 때는 최소한으로 투자하고 부하가 높아짐에 따라 확장해가기 쉽다는 것이고, 혹은 상당한 용도의 서버도 저렴하고 간단하게 준비할 수 있다는 것이다.

여러모로 빠르게 상황 대처가 쉽다는 점일 것이다.

## 규모 조정의 요소
> CPU 부하와 I/O 부하

스케일아웃은 하드웨어를 나열해서 성능을 높이는, 즉 하드웨어를 횡으로 전개해서 확장성을 확보해가게 된다.

이때 CPU 부하의 확장성을 확보하기는 쉽다.

예를 들면 웹 애플리케이션에서 계산을 수행하고 있을 때, 즉 HTTP 요청을 받아 DB에 질의하고 DB로부터 응답받은 데이터를 가공해서 HTML로 클라이언트에 반환할 때는 기본적으로 CPU 부하만 소요되는 부분이다.

이것은 나중에 설명할 서버 구성 중에 프록시나 AP 서버(application server)가 담당할 일이다.

한편 DB 서버 측면에서는 I/O 부하가 걸린다. 이는 대규모 데이터 및 DB라는 두 가지 관점에서 자세히 살펴보도록 하자.

## 웹 애플리케이션과 부하의 관계
웹 애플리케이션의 3단 구조에는 프록시, AP 서버, DB가 있다.

기본적으로 AP 서버에는 I/O 부하가 걸리지 않고 DB 측에 I/O 부하가 걸린다.

AP 서버는 CPU 부하만 걸리므로 분산이 간단하다. 그 이유는 기본적으로 데이터를 분산해서 갖고 있는 것이 아니기 때문에 대수를 늘리기만 하면 간단히 확장해갈 수 있다.

결국 새로운 서버를 추가하고자 한다면 원래 있던 서버와 완전히 동일한 구성을 갖는 서버, 심하게 말하면 복사본을 마련해서 추가하면 된다.

요청을 균등하게 분산하는 것은 로드밸런서라는 장치가 해준다. 이걸로 OK.

한편 I/O 부하에는 문제가 있다. DB를 함께 놓는다고 하면, 예를 들어 쓰기 요청이 발생했을 때 데이터 서버들끼리 데이터를 어떻게 동기화할 것인가라는 문제가 생긴다.

데이터를 어떻게 다른 DB 서버에 복사할 것인가라는 상황에 놓인다. 쓰기는 간단히 분산할 수가 없다.

## DB 확장성 확보의 어려움
이렇게, DB 확장성을 확보하는 것은 상당히 어렵다.

그리고, 앞서 설명한 바와 같이 디스크가 느리다는 문제도 여기에 영향을 미친다.

데이터가 커지면 커질수록 메모리에서 처리 못하고 디스크상에서 처리할 수 밖에 없는 요건이 늘어난다.

즉, 대규모 환경에서는 I/O 부하를 부담하고 있는 서버는 애초에 분산시키기 어려운데다가 디스크 I/O가 많이 발생하면 서버가 금새 느려지는 본질적인 문제가 있다.

### 두 종류의 부하와 웹 애플리케이션
부하는 크게 두가지로 분류된다.
- CPU 부하
- I/O 부하

예를 들어 대규모의 과학계산을 하는 프로그램이 있는데, 이 프로그램은 디스크 입출력은 하지 않지만 처리가 완료될 때까지 상당한 시간을 요한다고 하자.

이 프로그램의 처리속도는 CPU의 계산속도에 의존하고 있다. 이것이 바로 CPU에 부하를 주는 프로그램이다. 

한편, 디스크에 저장된 대량의 데이터에서 임의의 문서를 찾아내는 검색 프로그램이 있다고 하자.

이 검색 프로그램의 처리속도는 CPU가 아닌, 디스크의 읽기 속도, 즉 입출력에 의존할 것이다.

디스크가 빠르면 빠를수록 검색에 걸리는 시간은 짧아진다.

일반적으로 AP 서버는 DB로 부터 얻은 데이터를 가공해서 클라이언트로 전달하는 처리를 수행한다. 그 과정에서 대규모 I/O를 발생시키는 일은 드물다.

반면 웹 애ㅔ플리케이션을 구성하는 또 하나의 요소 시스템인 DB 서버는 데이터를 디스크로 부터 검색하는 것이 주된 일로, 특히 데이터가 대규모가 되면 될 수록 CPU에서의 계산시간보다도 I/O에 대한 영향이 커지는 I/O 바운드한 서버다.

<br>

# 강의7. 대규모 데이터를 다루기 위한 기초지식
## 프로그래머를 위한 대규모 데이터 기초
지금까지 살펴본 바와 같이 대규모 데이터는 메모리에서 처리하기 어렵고 디스크는 느리다. 또한 분산하기도 곤란하다는 어려움이 있다는 것을 알았다. 

대규모 데이터를 다루는 두 가지 관점에서 정리해 보았다.
- 프로그램을 작성할 때의 요령
- 프로그램 개발의 근간이 되는 기초라는 점에서 전제로서 알아두었으면 하는 것

## 대규모 데이터를 다루는 세 가지 급소
> 프로그램을 작성할 때의 요령

대규모 데이터, 이것을 다루는 요령(1)은 `어떻게 하면 메모리에서 처리를 마칠 수 있을까?`라는 점이다.

메모리에서 처리를 마쳐야 하는 이유는 앞서 설명한 대로 디스크 탐색 횟수가 확장성, 성능에 크게 영향을 주기 때문이다. 디스크 탐색 횟수를 최소화한다는 의미로 메모리를 활용하고자 한다.

요령(2)로는 `데이터량 증가에 강한 알고리즘을 사용하는 것`이다. 레코드 1000만 건이 있을 때 단순히 선형탐색으로 하면 1,000만 번 계산을 수행해야 하는데, Log Order인 알고리즘을 적용하면 수십 번 만에 마칠 수 있다는 기본적인 예가 있다.

요령(3)로는 `데이터 압축이나 검색기술과 같은 테크닉이 활용될 수 있는 국면이 있다.`

단적으로 말하면 압축해서 데이터량을 줄일 수 있다면 읽어내는 탐색 횟수도 적어지게 되므로 디스크 읽는 횟수를 최소화할 수 있다는 것이다.

또한 메모리에 캐싱하기 쉬워진다. 데이터가 크면 메모리에서 넘치거나 디스크에 저장해도 읽어내기에 시간이 걸리므로 압축이 중요해진다.

또한 검색이 중요한 이유는 확장성 면에서 DB에만 맡겨서 해결할 수 없을 때, 특정 용도에 특화된 검색엔진 등을 만들어서 해당 검색 시스템을 웹 애플리케이션에서 이용하는 형태로 전환한다면 속도를 제대로 확보할 수 있기 때문이다.

## 대규모 데이터를 다루기 전 3대 전제지식
> 프로그램 개발의 한층 아래 기초

프로그램을 만드는 입장에서는 알고리즘, 압축, 검색 등이 중요하다.

3대 전제지식을 소개한다.
1. OS 캐시
2. 분산을 고려해서 RDBMS를 운용할 때는 어떻게 해야만 하는가
3. 대규모 환경에서 알고리즘과 데이터 구조를 사용한다는 것은 어떤 것인가라는 점에 대해 살펴보도록 하자.

> Q. DB 서버를 늘리는 것과 동기화가 어려워지는 것이 관계가 있는 건가요?

A. 그렇다. 관계 있다. AP 서버는 늘리면 늘릴수록 점점 빨라지므로 부족해지면 늘리면 그만이다.

반면 DB 서버는 늘리더라도 의미가 없는 경우가 자주 있다. 이후에 자료가 좀 나오므로 거기서 다시 거론하도록 하자.
